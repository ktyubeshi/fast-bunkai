# FastBunkai Agent Notes

## Overview
FastBunkai is a Rust + Python hybrid implementation of the bunkai sentence boundary disambiguation pipeline. The project mirrors the public API of `bunkai.Bunkai`, enabling drop-in replacement via `from fast_bunkai import FastBunkai as Bunkai`. The Rust backend handles the heavy segmentation logic while Python maintains compatibility layers (annotations, Janome integration) for parity with the original library.

## Architecture
- **Rust core (`src/lib.rs`)**
  - Implements key annotators: face mark detection, emotion expressions, emoji detection, basic punctuation rules, dot/number exceptions, linebreak handling, and indirect quote filtering.
  - Uses PyO3 with abi3 bindings to expose a `segment(text)` function that returns all intermediate layers and final boundaries.
  - Works over Unicode character indices to match bunkai’s logic, including manual handling for surrogate pairs and multi-byte characters.
  - Keeps the pipeline thread-safe; segmentation runs under `py.allow_threads`, so Python GIL is released during heavy work.

- **Emoji Metadata (`src/emoji_data.rs`)**
  - Generated by `scripts/generate_emoji_data.py` using the `emoji` and `emojis` Python packages.
  - Provides a static mapping of Unicode codepoints to optional emoji categories to match bunkai’s target categories.
  - Regeneration is required when upstream emoji datasets change. Run: `uv run python scripts/generate_emoji_data.py`.

- **Python layer (`fast_bunkai/`)
  - `core.py` wraps the Rust `segment` function to expose `FastBunkaiSentenceBoundaryDisambiguation` (aliased to `FastBunkai`).
  - Builds Janome-based morphological spans to populate the `MorphAnnotatorJanome` layer, ensuring compatibility with bunkai’s annotations.
  - Uses dataclasses in `annotations.py` to mirror bunkai’s annotation objects (`SpanAnnotation`, `TokenResult`, etc.).

## Testing & Validation
- **Pytest Suite** (`tests/test_compatibility.py`)
  - Compares sentence splits, end-of-sentence indices, and morphological token surfaces against bunkai for multiple Japanese and English texts.
  - Edge cases（空文字・空白・多絵文字など）を含めた互換性検証と、スレッド／asyncio 並列実行の整合性テストを実施。
  - Run via `uv run pytest`.

- **Rust Unit Tests**
  - Example: `cargo test face_mark_detection_matches_reference` ensures the hand-rolled face-mark detector matches expected spans.

## Benchmarking
- Script: `scripts/benchmark.py`
  - Benchmarks JapaneseとEnglishの長文コーパスをそれぞれ繰り返し実行し、bunkaiとの速度比較を行う。
  - デフォルトでは内部で正確性チェックを実施してから計測する。
  - 実行例:
  ```bash
  uv run python scripts/benchmark.py --repeats 3 --jp-loops 100 --en-loops 100 --custom-loops 10
  ```
  - 出力例（2025-10-10計測）:
    - Japanese corpus (200 docs): bunkai 平均 255.24 ms, fast-bunkai 平均 5.63 ms → 約45.33倍高速。
    - English corpus (200 docs): bunkai 平均 210.63 ms, fast-bunkai 平均 4.94 ms → 約42.67倍高速。

## Development Workflow
1. Install dependencies & build editable wheel:
   ```bash
   uv sync --reinstall
   ```
2. 再生成が必要な場合は絵文字テーブルを更新:
   ```bash
   uv run python scripts/generate_emoji_data.py
   ```
3. テストを実行:
   ```bash
   uv run pytest
   cargo test face_mark_detection_matches_reference
   ```
4. ベンチマークで性能確認:
  ```bash
  uv run python scripts/benchmark.py --repeats 3 --jp-loops 100 --en-loops 100 --custom-loops 10
  ```
  *ベンチマークは時間がかかるため、GitHub Actions の `CI` ワークフローでのみ実行し、リリースフローではスキップする。*

## Tooling & Quality Gates
- **tox 環境**
  - `pytests`: `uv run pytest --maxfail=1 --durations=5`
  - `lint`: `uv run ruff check .`
  - `format-check`: `uv run ruff format --check --diff`
  - `typecheck`: `uv run pyright .`
  - `rust-fmt`: `cargo fmt --all -- --check`
  - `rust-clippy`: `cargo clippy --all-targets -- -D warnings`
- Python ライブラリのリンター／フォーマッタには Ruff（`tool.ruff`）を利用し、型チェックは Pyright (`tool.pyright`) を使用する。
- tox 実行例:
  ```bash
  uv run tox -e pytests,lint,typecheck,rust-fmt,rust-clippy
  ```

- GitHub Actions:
  - `CI`: PR/`main` で tox 全環境とベンチマークを実行。
  - `Publish to PyPI`: `v*` タグ push で起動し、`uv sync --locked` → `uv build` → `tests/smoke_test.py` → `uv publish`（Trusted Publishing 前提）。
## Thread Safety & Concurrency
- Rust側の `segment_impl` はArcやグローバル可変状態を保持せず、文字列ビューをローカルに確保するため、複数スレッドから安全に呼び出し可能。
- Python側も特別なキャッシュを持たず、FastBunkaiインスタンスはステートレスに複数スレッド／asyncタスクから利用できる設計となっている。

## 注意事項
- `FastBunkai` を `Bunkai` としてインポートする場合: `from fast_bunkai import FastBunkai as Bunkai`。
- 絵文字リストはemojiライブラリの更新に追随する必要があるため、バージョンアップ時は `scripts/generate_emoji_data.py` を再実行すること。
- ベンチマーク結果は稼働環境によって変動するため、公開前に該当環境で再計測すること。
