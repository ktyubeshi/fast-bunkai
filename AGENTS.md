# FastBunkai Agent Notes

## Overview
FastBunkai is a Rust + Python hybrid implementation of the bunkai sentence boundary disambiguation pipeline. The project mirrors the public API of `bunkai.Bunkai`, enabling drop-in replacement via `from fast_bunkai import FastBunkai as Bunkai`. The Rust backend handles the heavy segmentation logic while Python maintains compatibility layers (annotations, Janome integration) for parity with the original library.

See `README.md` for quick start instructions, CLI usage examples, up-to-date benchmarks (≈40–285× faster than pure Python bunkai on bundled corpora), and acknowledgements to the [megagonlabs/bunkai](https://github.com/megagonlabs/bunkai) project.

## Architecture
- **Rust core (`src/lib.rs`)**
  - Implements key annotators: face mark detection, emotion expressions, emoji detection, basic punctuation rules, dot/number exceptions, linebreak handling, and indirect quote filtering.
  - Uses PyO3 with abi3 bindings to expose a `segment(text)` function that returns all intermediate layers and final boundaries.
  - Works over Unicode character indices to match bunkai’s logic, including manual handling for surrogate pairs and multi-byte characters.
  - Keeps the pipeline thread-safe; segmentation runs under `py.allow_threads`, so Python GIL is released during heavy work.

- **Emoji Metadata (`src/emoji_data.rs`)**
  - Generated by `scripts/generate_emoji_data.py` using the `emoji` and `emojis` Python packages.
  - Provides a static mapping of Unicode codepoints to optional emoji categories to match bunkai’s target categories.
  - Regeneration is required when upstream emoji datasets change. Run: `uv run python scripts/generate_emoji_data.py`.

- **Python layer (`fast_bunkai/`)
  - `core.py` wraps the Rust `segment` function to expose `FastBunkaiSentenceBoundaryDisambiguation` (aliased to `FastBunkai`).
  - Builds Janome-based morphological spans to populate the `MorphAnnotatorJanome` layer, ensuring compatibility with bunkai’s annotations.
  - Uses dataclasses in `annotations.py` to mirror bunkai’s annotation objects (`SpanAnnotation`, `TokenResult`, etc.).

## Testing & Validation
- **Pytest Suite** (`tests/test_compatibility.py`)
  - Compares sentence splits, end-of-sentence indices, and morphological token surfaces against bunkai for multiple Japanese and English texts.
  - Edge cases（空文字・空白・多絵文字など）を含めた互換性検証と、スレッド／asyncio 並列実行の整合性テストを実施。
  - Run via `uv run pytest`.

- **Rust Unit Tests**
  - Example: `cargo test face_mark_detection_matches_reference` ensures the hand-rolled face-mark detector matches expected spans.

## Benchmarking
- Script: `scripts/benchmark.py`
  - Benchmarks JapaneseとEnglishの長文コーパスをそれぞれ繰り返し実行し、bunkaiとの速度比較を行う。
  - `custom`（Long text）コーパスは `tests/texts/` ディレクトリの長文サンプルを使用し、絵文字・句読点・疑問符が混在するケースで差を検証する。
  - デフォルトでは内部で正確性チェックを実施してから計測する。
  - 実行例:
  ```bash
  uv run python scripts/benchmark.py --repeats 3 --jp-loops 100 --en-loops 100 --custom-loops 10
  ```
  - 出力例（2025-10-10計測）:
    - Japanese corpus (200 docs): bunkai 平均 255.24 ms, fast-bunkai 平均 5.63 ms → 約45.33倍高速。
    - English corpus (200 docs): bunkai 平均 210.63 ms, fast-bunkai 平均 4.94 ms → 約42.67倍高速。

## Development Workflow
1. Install dependencies & build editable wheel:
   ```bash
   uv sync --reinstall
   ```
2. 再生成が必要な場合は絵文字テーブルを更新:
   ```bash
   uv run python scripts/generate_emoji_data.py
   ```
3. テストを実行:
   ```bash
   uv run pytest
   cargo test face_mark_detection_matches_reference
   ```
4. ベンチマークで性能確認:
  ```bash
  uv run python scripts/benchmark.py --repeats 3 --jp-loops 100 --en-loops 100 --custom-loops 10
  ```
  *ベンチマークは時間がかかるため、GitHub Actions の `CI` ワークフローでのみ実行し、リリースフローではスキップする。*

## Release Workflow
1. ブランチを最新 `origin/main` から切る: `git checkout -b release/vX.Y.Z origin/main`
2. `pyproject.toml`・`Cargo.toml`・`Cargo.lock` を新バージョンへ更新し、`CHANGELOG.md` にエントリを追加する。
3. 変更点のサマリを `CHANGELOG.md` に整理し、必要に応じて `README.md` などの公開情報も更新する。
4. テストを実行: `uv run tox`。必要なら公開ベンチも `scripts/benchmark.py` を参照して実行する。
5. PRを作成する前に、`git diff` や `git diff origin/main...` などで実際の差分を細部までレビューし、コミットログだけで判断しないこと。CHANGELOG と PR 内容が差分と合致しているか必ず確認する。
6. コミット後、`gh pr create --base main --head release/vX.Y.Z --title "Release vX.Y.Z" --body "<要約/テスト結果>` を使ってリリースPRを作成する。`gh` が利用できない場合は手動でPRを作成し、本文に v前バージョン からの差分を記載する。
7. PRをマージ後、ローカルを `main` に戻しタグを作成: `git tag vX.Y.Z && git push origin vX.Y.Z`。Trusted Publishing が有効なためタグ push で `.github/workflows/publish.yml` が走る。
8. リリースノートを追加する場合は `gh release create vX.Y.Z --generate-notes` などを利用し、PyPI公開と同時にGitHub Releasesも更新する。

## Tooling & Quality Gates
- **tox 環境**
  - `pytests`: `uv run pytest --maxfail=1 --durations=5`
  - `lint`: `uv run ruff check .`
  - `format-check`: `uv run ruff format --check --diff`
  - `typecheck`: `uv run pyright .`
  - `rust-fmt`: `cargo fmt --all -- --check`
  - `rust-clippy`: `cargo clippy --all-targets -- -D warnings`
- Python ライブラリのリンター／フォーマッタには Ruff（`tool.ruff`）を利用し、型チェックは Pyright (`tool.pyright`) を使用する。
- tox 実行例:
  ```bash
  uv run tox -e pytests,lint,typecheck,rust-fmt,rust-clippy
  ```

- GitHub Actions:
  - `CI`: PR/`main` で tox 全環境とベンチマークを実行。
  - `Publish to PyPI`: `v*` タグ push で起動し、`uv sync --locked` → `uv build` → `tests/smoke_test.py` → `uv publish`（Trusted Publishing 前提）。
## Thread Safety & Concurrency
- Rust側の `segment_impl` はArcやグローバル可変状態を保持せず、文字列ビューをローカルに確保するため、複数スレッドから安全に呼び出し可能。
- Python側も特別なキャッシュを持たず、FastBunkaiインスタンスはステートレスに複数スレッド／asyncタスクから利用できる設計となっている。

## 注意事項
- `FastBunkai` を `Bunkai` としてインポートする場合: `from fast_bunkai import FastBunkai as Bunkai`。
- 絵文字リストはemojiライブラリの更新に追随する必要があるため、バージョンアップ時は `scripts/generate_emoji_data.py` を再実行すること。
- ベンチマーク結果は稼働環境によって変動するため、公開前に該当環境で再計測すること。
