mod emoji_data;

use memchr::memmem::Finder;
use memchr::{memchr3_iter, memchr_iter};
use once_cell::sync::Lazy;
use rustc_hash::FxHashSet;
use std::cmp::Ordering;
use std::collections::HashMap;

const TARGET_EMOJI_FLAGS: u8 = emoji_data::FLAG_SMILEYS_EMOTION | emoji_data::FLAG_SYMBOLS;
const INDIRECT_RULE_TARGETS: &[&str] = &[
    "first",
    "BasicRule",
    "LinebreakForceAnnotator",
    "EmojiAnnotator",
    "EmotionExpressionAnnotator",
    "FaceMarkDetector",
];

const MORPHEME_RULES: &[&[&str]] = &[
    &["て"],
    &["の"],
    &["と"],
    &["って"],
    &["という"],
    &["に"],
    &["など"],
    &["くらい", "の"],
    &["くらい", "です"],
    &["くらい", "でし"],
    &["も", "あり"],
    &["ほど", "でし"],
];

const FACE_SYMBOL_RANGES: &[(char, char)] = &[
    ('!', '/'),
    (':', '@'),
    ('[', '`'),
    ('{', '~'),
    ('！', '／'),
    ('：', '＠'),
    ('［', '｀'),
    ('｛', '～'),
    ('\u{00A1}', '\u{0FFF}'),
    ('\u{1000}', '\u{2FFF}'),
];

const FACE_SYMBOL_EXTRA: &[char] = &['\u{4E00}', '艸'];

const ASCII_ALNUM_RANGES: &[(char, char)] = &[('0', '9'), ('A', 'Z'), ('a', 'z')];
const FULLWIDTH_ALNUM_RANGES: &[(char, char)] = &[('０', '９'), ('Ａ', 'Ｚ'), ('ａ', 'ｚ')];

const EMOTION_WORDS: &[&str] = &[
    "笑", "泣", "汗", "涙", "怒", "嬉", "爆", "驚", "喜", "悲", "謎", "恥", "焦", "苦", "照", "憂",
    "笑い", "わら", "泣き", "怒り", "照れ",
];
const EMOTION_SYMBOLS: &[char] = &['…', '★', '☆', '♪'];
const EMOTION_PUNCTUATION: &[char] = &['。', '!', '?', '！', '？', '．', '.'];

static FULLWIDTH_BREAK_FINDERS: Lazy<[Finder<'static>; 4]> =
    Lazy::new(|| ["。", "！", "？", "．"].map(|pattern| Finder::new(pattern.as_bytes())));

static FACE_OPEN_FINDERS: Lazy<[Finder<'static>; 1]> = Lazy::new(|| [Finder::new("（".as_bytes())]);

const BMP_LIMIT: usize = 0x1_0000;

static EMOJI_FLAGS_BMP: Lazy<[u8; BMP_LIMIT]> = Lazy::new(|| {
    let mut table = [0u8; BMP_LIMIT];
    for range in emoji_data::EMOJI_RANGES {
        let start = range.start as usize;
        if start >= BMP_LIMIT {
            continue;
        }
        let end = usize::min(range.end as usize, BMP_LIMIT - 1);
        for idx in start..=end {
            table[idx] |= range.flags;
        }
    }
    table
});

/// Sentence boundary span generated by the segmentation pipeline.
#[derive(Clone, Debug)]
pub struct Span {
    pub rule_name: &'static str,
    pub start: usize,
    pub end: usize,
    pub split_type: Option<&'static str>,
    pub split_value: Option<String>,
}

/// Named layer containing the spans emitted by a specific rule.
#[derive(Clone, Debug)]
pub struct Layer {
    pub name: &'static str,
    pub spans: Vec<Span>,
}

/// Final segmentation output containing rule layers and resolved sentence boundaries.
#[derive(Clone, Debug)]
pub struct Segmentation {
    pub layers: Vec<Layer>,
    pub final_boundaries: Vec<usize>,
}

impl Segmentation {
    /// Returns contiguous ranges of Unicode scalar indices that form each sentence.
    pub fn sentence_char_ranges(&self) -> Vec<(usize, usize)> {
        let mut ranges = Vec::with_capacity(self.final_boundaries.len());
        let mut start = 0usize;
        for &end in &self.final_boundaries {
            if end < start {
                continue;
            }
            ranges.push((start, end));
            start = end;
        }
        ranges
    }

    /// Returns contiguous ranges of byte offsets that form each sentence for the provided text.
    pub fn sentence_byte_ranges(&self, text: &str) -> Vec<(usize, usize)> {
        let mut char_to_byte: Vec<usize> = text.char_indices().map(|(idx, _)| idx).collect();
        char_to_byte.push(text.len());

        let mut ranges = Vec::with_capacity(self.final_boundaries.len());
        let mut start_char = 0usize;
        for &end_char in &self.final_boundaries {
            if end_char < start_char {
                continue;
            }
            let start_byte = char_to_byte.get(start_char).copied().unwrap_or(text.len());
            let end_byte = char_to_byte.get(end_char).copied().unwrap_or(text.len());
            ranges.push((start_byte, end_byte));
            start_char = end_char;
        }
        ranges
    }
}

/// Stateless segmenter wrapper that mirrors the Python extension behaviour.
#[derive(Clone, Copy, Default)]
pub struct Segmenter;

impl Segmenter {
    pub fn new() -> Self {
        Self
    }

    pub fn segment(&self, text: &str) -> Segmentation {
        segment_impl(text)
    }
}

pub fn segment(text: &str) -> Segmentation {
    Segmenter::new().segment(text)
}

pub fn segment_boundaries(text: &str) -> Vec<usize> {
    let view = TextView::new(text);
    let state = build_pipeline(&view);
    state.into_final_boundaries()
}

#[derive(Clone, Debug, Copy)]
struct SpanRecord<'a> {
    rule_name: &'static str,
    start: usize,
    end: usize,
    split_type: Option<&'static str>,
    split_value: Option<&'a str>,
}

#[derive(Clone)]
struct LayerOutput<'a> {
    name: &'static str,
    spans: Vec<SpanRecord<'a>>,
}

struct PipelineState<'a> {
    layers: Vec<LayerOutput<'a>>,
    name_to_index: HashMap<&'static str, usize>,
    final_index: usize,
}

impl<'a> PipelineState<'a> {
    fn new(char_len: usize) -> Self {
        let sentinel_start = if char_len == 0 { 0 } else { char_len - 1 };
        let sentinel = SpanRecord {
            rule_name: "first",
            start: sentinel_start,
            end: char_len,
            split_type: None,
            split_value: None,
        };
        let layer = LayerOutput {
            name: "first",
            spans: vec![sentinel],
        };
        let mut name_to_index = HashMap::with_capacity(8);
        name_to_index.insert("first", 0);
        Self {
            layers: {
                let mut layers = Vec::with_capacity(8);
                layers.push(layer);
                layers
            },
            name_to_index,
            final_index: 0,
        }
    }

    fn final_spans(&self) -> &[SpanRecord<'a>] {
        &self.layers[self.final_index].spans
    }

    fn get_layer(&self, name: &'static str) -> Option<&[SpanRecord<'a>]> {
        self.name_to_index
            .get(name)
            .map(|idx| self.layers[*idx].spans.as_slice())
    }

    fn add_layer(&mut self, name: &'static str, spans: Vec<SpanRecord<'a>>) {
        let idx = self.layers.len();
        self.layers.push(LayerOutput { name, spans });
        self.name_to_index.insert(name, idx);
        self.final_index = idx;
    }

    fn add_forward_rule(&mut self, name: &'static str, spans: Vec<SpanRecord<'a>>) {
        let filtered = filter_previous_rule_same_span(spans, self.final_spans());
        self.add_layer(name, filtered);
    }

    fn into_output(self) -> PipelineOutput<'a> {
        let final_boundaries = finalize_boundaries_from_iter(
            self.layers[self.final_index]
                .spans
                .iter()
                .map(|span| span.end),
        );
        PipelineOutput {
            layers: self.layers,
            final_boundaries,
        }
    }

    fn into_final_boundaries(self) -> Vec<usize> {
        let final_spans = self
            .layers
            .into_iter()
            .nth(self.final_index)
            .map(|layer| layer.spans)
            .unwrap_or_default();
        finalize_boundaries_from_iter(final_spans.into_iter().map(|span| span.end))
    }
}

struct PipelineOutput<'a> {
    layers: Vec<LayerOutput<'a>>,
    final_boundaries: Vec<usize>,
}

impl<'a> From<PipelineOutput<'a>> for Segmentation {
    fn from(output: PipelineOutput<'a>) -> Self {
        let layers = output
            .layers
            .into_iter()
            .map(|layer| Layer {
                name: layer.name,
                spans: layer
                    .spans
                    .into_iter()
                    .map(|span| {
                        let SpanRecord {
                            rule_name,
                            start,
                            end,
                            split_type,
                            split_value,
                        } = span;
                        let split_value = split_value.map(|value| value.to_string());
                        Span {
                            rule_name,
                            start,
                            end,
                            split_type,
                            split_value,
                        }
                    })
                    .collect(),
            })
            .collect();

        Self {
            layers,
            final_boundaries: output.final_boundaries,
        }
    }
}

fn finalize_boundaries_from_iter<I>(iter: I) -> Vec<usize>
where
    I: Iterator<Item = usize>,
{
    let mut final_boundaries: Vec<usize> = iter.collect();
    final_boundaries.sort_unstable();
    final_boundaries.dedup();
    final_boundaries
}

struct TextView<'a> {
    text: &'a str,
    chars: Vec<char>,
    char_to_byte: Vec<u32>,
}

impl<'a> TextView<'a> {
    fn new(text: &'a str) -> Self {
        let chars: Vec<char> = text.chars().collect();
        let char_to_byte: Vec<u32> = text
            .char_indices()
            .map(|(byte_idx, _)| {
                u32::try_from(byte_idx)
                    .expect("fast-bunkai currently supports texts smaller than 4 GiB")
            })
            .collect();
        Self {
            text,
            chars,
            char_to_byte,
        }
    }

    fn char_len(&self) -> usize {
        self.chars.len()
    }

    fn char_at(&self, index: usize) -> Option<char> {
        self.chars.get(index).copied()
    }

    fn slice(&self, start: usize, end: usize) -> &'a str {
        let start_byte = if start >= self.char_to_byte.len() {
            self.text.len()
        } else {
            self.char_to_byte[start] as usize
        };
        let end_byte = if end >= self.char_to_byte.len() {
            self.text.len()
        } else {
            self.char_to_byte[end] as usize
        };
        &self.text[start_byte..end_byte]
    }

    fn starts_with(&self, index: usize, pattern: &str) -> bool {
        let mut cursor = index;
        for ch in pattern.chars() {
            match self.char_at(cursor) {
                Some(current) if current == ch => {
                    cursor += 1;
                }
                _ => return false,
            }
        }
        true
    }

    fn as_bytes(&self) -> &'a [u8] {
        self.text.as_bytes()
    }

    fn byte_to_char_index(&self, byte_offset: usize) -> Option<usize> {
        let byte_u32 = u32::try_from(byte_offset).ok()?;
        self.char_to_byte.binary_search(&byte_u32).ok()
    }
}

#[derive(Clone)]
struct EmojiSpan {
    start: usize,
    end: usize,
    flags: u8,
}

#[inline]
fn emoji_flags(codepoint: u32) -> u8 {
    if codepoint <= 0x7F {
        return 0;
    }
    if codepoint < BMP_LIMIT as u32 {
        return (*EMOJI_FLAGS_BMP)[codepoint as usize];
    }
    let mut low = 0usize;
    let mut high = emoji_data::EMOJI_RANGES.len();
    while low < high {
        let mid = (low + high) / 2;
        let range = &emoji_data::EMOJI_RANGES[mid];
        if codepoint < range.start {
            high = mid;
        } else if codepoint > range.end {
            low = mid + 1;
        } else {
            return range.flags;
        }
    }
    0
}

fn is_in_ranges(ch: char, ranges: &[(char, char)]) -> bool {
    ranges.iter().any(|&(start, end)| start <= ch && ch <= end)
}

fn is_face_symbol_prefix_suffix(ch: char) -> bool {
    if matches!(ch, '(' | ')' | '（' | '）') {
        return false;
    }
    is_in_ranges(ch, FACE_SYMBOL_RANGES) || FACE_SYMBOL_EXTRA.contains(&ch)
}

fn is_face_symbol2(ch: char) -> bool {
    is_face_symbol_prefix_suffix(ch)
}

fn is_ascii_alnum(ch: char) -> bool {
    is_in_ranges(ch, ASCII_ALNUM_RANGES)
}

fn is_fullwidth_alnum(ch: char) -> bool {
    is_in_ranges(ch, FULLWIDTH_ALNUM_RANGES)
}

fn is_face_symbol1(ch: char) -> bool {
    is_ascii_alnum(ch) || is_fullwidth_alnum(ch) || is_face_symbol2(ch)
}

fn find_face_marks<'a>(view: &'a TextView<'a>) -> Vec<SpanRecord<'a>> {
    let len = view.char_len();
    if len == 0 {
        return Vec::new();
    }

    let mut spans: Vec<SpanRecord<'a>> = Vec::with_capacity(len / 8);
    let bytes = view.as_bytes();
    let mut seeds: Vec<usize> = Vec::with_capacity(len / 16 + 1);

    for byte in memchr_iter(b'(', bytes) {
        if let Some(idx) = view.byte_to_char_index(byte) {
            seeds.push(idx);
        }
    }
    for finder in FACE_OPEN_FINDERS.iter() {
        for byte in finder.find_iter(bytes) {
            if let Some(idx) = view.byte_to_char_index(byte) {
                seeds.push(idx);
            }
        }
    }

    if seeds.is_empty() {
        return spans;
    }

    seeds.sort_unstable();
    seeds.dedup();

    let mut next_uncovered = 0usize;
    for seed in seeds {
        if seed < next_uncovered {
            continue;
        }

        let mut cursor = seed + 1;
        let mut has_symbol2 = false;
        while cursor < len {
            let current = view.char_at(cursor).unwrap_or('\0');
            if !is_face_symbol1(current) {
                break;
            }
            if is_face_symbol2(current) {
                has_symbol2 = true;
            }
            cursor += 1;
        }
        if !has_symbol2 {
            next_uncovered = seed + 1;
            continue;
        }
        if cursor >= len {
            next_uncovered = seed + 1;
            continue;
        }
        let closing = view.char_at(cursor).unwrap_or('\0');
        if closing != ')' && closing != '）' {
            next_uncovered = seed + 1;
            continue;
        }
        let mut end = cursor + 1;
        while end < len && is_face_symbol_prefix_suffix(view.char_at(end).unwrap_or('\0')) {
            end += 1;
        }
        let mut start = seed;
        while start > 0 && is_face_symbol_prefix_suffix(view.char_at(start - 1).unwrap_or('\0')) {
            start -= 1;
        }

        spans.push(SpanRecord {
            rule_name: "FaceMarkDetector",
            start,
            end,
            split_type: Some("facemark"),
            split_value: Some(view.slice(start, end)),
        });
        next_uncovered = end;
    }

    spans
}

fn find_emotion_expressions<'a>(view: &'a TextView<'a>) -> Vec<SpanRecord<'a>> {
    let mut spans: Vec<SpanRecord<'a>> = Vec::with_capacity(view.char_len() / 8);
    let len = view.char_len();

    for idx in 0..len {
        let ch = view.char_at(idx).unwrap_or('\0');
        if ch != '(' && ch != '（' {
            continue;
        }
        for word in EMOTION_WORDS {
            let word_len = word.chars().count();
            let start_word = idx + 1;
            let end_word = start_word + word_len;
            if end_word >= len {
                continue;
            }
            if view.slice(start_word, end_word) == *word {
                let closing = view.char_at(end_word).unwrap_or('\0');
                if closing == ')' || closing == '）' {
                    let end = end_word + 1;
                    spans.push(SpanRecord {
                        rule_name: "EmotionExpressionAnnotator",
                        start: idx,
                        end,
                        split_type: Some("EmotionExpressionAnnotator"),
                        split_value: Some(view.slice(idx, end)),
                    });
                    break;
                }
            }
        }
    }

    let mut idx = 0usize;
    while idx < len {
        let ch = view.char_at(idx).unwrap_or('\0');
        if !EMOTION_SYMBOLS.contains(&ch) {
            idx += 1;
            continue;
        }
        let start = idx;
        while idx < len && EMOTION_SYMBOLS.contains(&view.char_at(idx).unwrap_or('\0')) {
            idx += 1;
        }
        let mut end = idx;
        if idx < len {
            let next = view.char_at(idx).unwrap_or('\0');
            if EMOTION_PUNCTUATION.contains(&next) {
                idx += 1;
                end += 1;
            }
        }
        spans.push(SpanRecord {
            rule_name: "EmotionExpressionAnnotator",
            start,
            end,
            split_type: Some("EmotionExpressionAnnotator"),
            split_value: Some(view.slice(start, end)),
        });
    }

    unify_span_annotations(spans)
}

#[inline]
fn is_basic_break_char(ch: char) -> bool {
    matches!(ch, '.' | '!' | '?' | '。' | '！' | '？' | '．')
}

fn build_basic_rule_spans<'a>(view: &'a TextView<'a>) -> Vec<SpanRecord<'a>> {
    let len = view.char_len();
    if len == 0 {
        return Vec::new();
    }

    let mut candidate_indices: Vec<usize> = Vec::with_capacity(len / 4 + 1);
    let bytes = view.as_bytes();

    for byte in memchr3_iter(b'.', b'!', b'?', bytes) {
        if let Some(idx) = view.byte_to_char_index(byte) {
            candidate_indices.push(idx);
        }
    }

    for finder in FULLWIDTH_BREAK_FINDERS.iter() {
        for byte in finder.find_iter(bytes) {
            if let Some(idx) = view.byte_to_char_index(byte) {
                candidate_indices.push(idx);
            }
        }
    }

    if candidate_indices.is_empty() {
        return Vec::new();
    }

    candidate_indices.sort_unstable();
    candidate_indices.dedup();

    let mut spans: Vec<SpanRecord<'a>> = Vec::with_capacity(candidate_indices.len());
    let mut pos = 0usize;

    while pos < candidate_indices.len() {
        let start = candidate_indices[pos];
        if start >= len {
            break;
        }

        let mut idx = start + 1;
        while idx < len && is_basic_break_char(view.char_at(idx).unwrap_or('\0')) {
            idx += 1;
        }

        let mut end = idx;
        while idx < len {
            let next = view.char_at(idx).unwrap_or('\0');
            if !next.is_whitespace() {
                break;
            }
            idx += 1;
            end = idx;
        }

        spans.push(SpanRecord {
            rule_name: "BasicRule",
            start,
            end,
            split_type: Some("BasicRule"),
            split_value: Some(view.slice(start, end)),
        });

        pos += 1;
        while pos < candidate_indices.len() && candidate_indices[pos] < idx {
            pos += 1;
        }
    }

    spans
}

fn build_pipeline<'a>(view: &'a TextView<'a>) -> PipelineState<'a> {
    let mut state = PipelineState::new(view.char_len());

    let face_spans = find_face_marks(view);
    state.add_forward_rule("FaceMarkDetector", face_spans);

    let emotion_spans = find_emotion_expressions(view);
    state.add_forward_rule("EmotionExpressionAnnotator", emotion_spans);

    let emoji_spans = build_emoji_spans(view);
    state.add_forward_rule("EmojiAnnotator", emoji_spans);

    let basic_rule_spans = build_basic_rule_spans(view);
    state.add_forward_rule("BasicRule", basic_rule_spans);

    apply_indirect_quote(view, &mut state);
    apply_dot_exception(view, &mut state);
    apply_number_exception(view, &mut state);
    apply_linebreak_force(view, &mut state);

    state
}

fn segment_impl(text: &str) -> Segmentation {
    let view = TextView::new(text);
    let state = build_pipeline(&view);
    let output = state.into_output();
    Segmentation::from(output)
}

fn build_emoji_spans<'a>(view: &'a TextView<'a>) -> Vec<SpanRecord<'a>> {
    let spans = find_emoji_spans(view);
    spans
        .into_iter()
        .filter(|span| span.end > span.start)
        .filter(|span| span.flags & TARGET_EMOJI_FLAGS != 0)
        .map(|span| SpanRecord {
            rule_name: "EmojiAnnotator",
            start: span.start,
            end: span.end,
            split_type: Some("EmojiAnnotator"),
            split_value: Some(view.slice(span.start, span.end)),
        })
        .collect()
}

fn find_emoji_spans(view: &TextView<'_>) -> Vec<EmojiSpan> {
    let mut spans: Vec<EmojiSpan> = Vec::with_capacity(view.char_len() / 6);
    let char_len = view.char_len();
    let mut in_span = false;
    let mut start = 0usize;
    let mut aggregated_flags = 0u8;

    for idx in 0..char_len {
        let ch = view.char_at(idx).unwrap_or('\0');
        let flags = emoji_flags(ch as u32);
        if flags == 0 {
            if in_span {
                spans.push(EmojiSpan {
                    start,
                    end: idx,
                    flags: aggregated_flags,
                });
                aggregated_flags = 0;
                in_span = false;
            }
            continue;
        }

        if !in_span {
            in_span = true;
            start = idx;
            aggregated_flags = 0;
        }
        aggregated_flags |= flags;

        let next_flags = if idx + 1 < char_len {
            let next_ch = view.char_at(idx + 1).unwrap_or('\0') as u32;
            emoji_flags(next_ch)
        } else {
            0
        };
        if next_flags == 0 {
            spans.push(EmojiSpan {
                start,
                end: idx + 1,
                flags: aggregated_flags,
            });
            aggregated_flags = 0;
            in_span = false;
        }
    }

    if in_span {
        spans.push(EmojiSpan {
            start,
            end: char_len,
            flags: aggregated_flags,
        });
    }

    spans
}

fn apply_indirect_quote<'a>(view: &'a TextView<'a>, state: &mut PipelineState<'a>) {
    let mut collected: Vec<SpanRecord<'a>> = Vec::with_capacity(state.final_spans().len());
    for &target in INDIRECT_RULE_TARGETS {
        if let Some(layer) = state.get_layer(target) {
            for span in layer {
                if is_exception_particle(view, span.start, span.end) {
                    continue;
                }
                collected.push(*span);
            }
        }
    }
    let unified = unify_span_annotations(collected);
    state.add_layer("IndirectQuoteExceptionAnnotator", unified);
}

fn is_exception_particle(view: &TextView<'_>, _start: usize, end: usize) -> bool {
    if end >= view.char_len() {
        return false;
    }
    let mut idx = end;
    if idx >= view.char_len() {
        return false;
    }
    while view.char_at(idx) == Some('\n') && idx + 1 < view.char_len() {
        idx += 1;
    }
    for rule in MORPHEME_RULES {
        if matches_rule(view, idx, rule) {
            return true;
        }
    }
    false
}

fn matches_rule(view: &TextView<'_>, mut index: usize, rule: &[&str]) -> bool {
    for part in rule {
        if !view.starts_with(index, part) {
            return false;
        }
        index += part.chars().count();
    }
    true
}

fn unify_span_annotations<'a>(mut spans: Vec<SpanRecord<'a>>) -> Vec<SpanRecord<'a>> {
    if spans.is_empty() {
        return spans;
    }

    spans.sort_unstable_by(|a, b| {
        (a.start, a.end, a.rule_name, a.split_value).cmp(&(
            b.start,
            b.end,
            b.rule_name,
            b.split_value,
        ))
    });

    spans.dedup_by(|a, b| {
        a.start == b.start
            && a.end == b.end
            && a.rule_name == b.rule_name
            && a.split_value == b.split_value
    });

    spans.sort_unstable_by(|a, b| match a.start.cmp(&b.start) {
        Ordering::Equal => a.end.cmp(&b.end),
        other => other,
    });
    spans
}

fn apply_dot_exception<'a>(view: &'a TextView<'a>, state: &mut PipelineState<'a>) {
    let mut filtered: Vec<SpanRecord<'a>> = Vec::with_capacity(state.final_spans().len());
    for span in state.final_spans().iter() {
        if is_exception_numeric(view, span.start) || is_exception_mailaddress(view, span.start) {
            continue;
        }
        filtered.push(*span);
    }
    state.add_layer("DotExceptionAnnotator", filtered);
}

fn is_exception_numeric(view: &TextView<'_>, index: usize) -> bool {
    if index == 0 {
        return false;
    }
    if index + 1 >= view.char_len() {
        return false;
    }
    match view.char_at(index) {
        Some('.') | Some('．') => {}
        _ => return false,
    }
    let prev_char = view.char_at(index - 1).unwrap_or('\0');
    let next_char = view.char_at(index + 1).unwrap_or('\0');
    is_numeric_char(prev_char) && is_numeric_char(next_char)
}

fn is_numeric_char(ch: char) -> bool {
    matches!(
        ch,
        '0' | '1'
            | '2'
            | '3'
            | '4'
            | '5'
            | '6'
            | '7'
            | '8'
            | '9'
            | '０'
            | '１'
            | '２'
            | '３'
            | '４'
            | '５'
            | '６'
            | '７'
            | '８'
            | '９'
            | '〇'
            | '一'
            | '二'
            | '三'
            | '四'
            | '五'
            | '六'
            | '七'
            | '八'
            | '九'
            | '十'
            | '百'
            | '千'
            | '万'
            | '億'
            | '兆'
            | '京'
    )
}

fn is_exception_mailaddress(view: &TextView<'_>, index: usize) -> bool {
    if index == 0 {
        return false;
    }
    if index + 1 >= view.char_len() {
        return false;
    }
    match view.char_at(index) {
        Some('.') | Some('．') => {}
        _ => return false,
    }
    let prev_char = view.char_at(index - 1).unwrap_or('\0');
    let next_char = view.char_at(index + 1).unwrap_or('\0');
    is_mail_char(prev_char) && is_mail_char(next_char)
}

fn is_mail_char(ch: char) -> bool {
    ch.is_ascii_alphanumeric()
}

fn apply_number_exception<'a>(view: &'a TextView<'a>, state: &mut PipelineState<'a>) {
    let mut filtered: Vec<SpanRecord<'a>> = Vec::with_capacity(state.final_spans().len());
    for span in state.final_spans().iter() {
        if is_exception_no(view, span) {
            continue;
        }
        filtered.push(*span);
    }
    state.add_layer("NumberExceptionAnnotator", filtered);
}

fn is_exception_no(view: &TextView<'_>, span: &SpanRecord<'_>) -> bool {
    if span.start < 2 {
        return false;
    }
    if span.end >= view.char_len() {
        return false;
    }
    let dot_char = view.char_at(span.start).unwrap_or('\0');
    if !matches!(dot_char, '.' | '．') {
        return false;
    }
    let n_char = view.char_at(span.start - 2).unwrap_or('\0');
    let o_char = view.char_at(span.start - 1).unwrap_or('\0');
    if !matches!(n_char, 'N' | 'n' | 'Ｎ' | 'ｎ') {
        return false;
    }
    if !matches!(o_char, 'O' | 'o' | 'Ｏ' | 'ｏ') {
        return false;
    }
    let next_char = view.char_at(span.end).unwrap_or('\0');
    next_char.is_ascii_digit()
}

fn collect_linebreak_spans(view: &TextView<'_>) -> Vec<(usize, usize)> {
    let len = view.char_len();
    if len == 0 {
        return Vec::new();
    }

    let mut spans: Vec<(usize, usize)> = Vec::with_capacity(len / 4);
    let bytes = view.as_bytes();
    let mut last_covered = 0usize;
    let mut char_index_cursor = 0usize;
    let char_to_byte = &view.char_to_byte;

    for newline_byte in memchr_iter(b'\n', bytes) {
        while char_index_cursor < char_to_byte.len()
            && (char_to_byte[char_index_cursor] as usize) < newline_byte
        {
            char_index_cursor += 1;
        }
        if char_index_cursor >= char_to_byte.len() {
            break;
        }
        let char_start = char_to_byte[char_index_cursor] as usize;
        if char_start != newline_byte {
            continue;
        }
        let newline_char_idx = char_index_cursor;
        char_index_cursor += 1;

        if newline_char_idx < last_covered {
            continue;
        }

        let mut start = newline_char_idx;
        while start > 0 {
            let prev = view.char_at(start - 1).unwrap_or('\0');
            if !prev.is_whitespace() {
                break;
            }
            start -= 1;
        }

        let mut end = newline_char_idx + 1;
        while end < len {
            let next = view.char_at(end).unwrap_or('\0');
            if !next.is_whitespace() {
                break;
            }
            end += 1;
        }

        spans.push((start, end));
        last_covered = end;
    }

    spans
}

fn apply_linebreak_force<'a>(view: &'a TextView<'a>, state: &mut PipelineState<'a>) {
    let linebreak_spans = collect_linebreak_spans(view);
    let final_spans = state.final_spans().to_vec();
    if linebreak_spans.is_empty() {
        state.add_layer("LinebreakForceAnnotator", final_spans);
        return;
    }

    let mut merged: Vec<SpanRecord<'a>> =
        Vec::with_capacity(final_spans.len() + linebreak_spans.len());
    let mut finals_index = 0usize;
    let mut linebreak_index = 0usize;

    while finals_index < final_spans.len() && linebreak_index < linebreak_spans.len() {
        let span = &final_spans[finals_index];
        let (lb_start, lb_end) = linebreak_spans[linebreak_index];
        if span.end == lb_start {
            merged.push(SpanRecord {
                rule_name: "LinebreakForceAnnotator",
                start: lb_start,
                end: lb_end,
                split_type: Some("linebreak"),
                split_value: Some(view.slice(lb_start, lb_end)),
            });
            finals_index += 1;
            linebreak_index += 1;
            continue;
        }
        if span.end < lb_start {
            merged.push(*span);
            finals_index += 1;
        } else {
            merged.push(SpanRecord {
                rule_name: "LinebreakForceAnnotator",
                start: lb_start,
                end: lb_end,
                split_type: Some("linebreak"),
                split_value: Some(view.slice(lb_start, lb_end)),
            });
            linebreak_index += 1;
        }
    }

    while finals_index < final_spans.len() {
        merged.push(final_spans[finals_index]);
        finals_index += 1;
    }
    while linebreak_index < linebreak_spans.len() {
        let (lb_start, lb_end) = linebreak_spans[linebreak_index];
        merged.push(SpanRecord {
            rule_name: "LinebreakForceAnnotator",
            start: lb_start,
            end: lb_end,
            split_type: Some("linebreak"),
            split_value: Some(view.slice(lb_start, lb_end)),
        });
        linebreak_index += 1;
    }

    state.add_layer("LinebreakForceAnnotator", merged);
}

fn filter_previous_rule_same_span<'a>(
    current: Vec<SpanRecord<'a>>,
    previous: &[SpanRecord<'a>],
) -> Vec<SpanRecord<'a>> {
    let mut prev_keys: FxHashSet<(usize, usize)> =
        FxHashSet::with_capacity_and_hasher(previous.len(), Default::default());
    for span in previous {
        prev_keys.insert((span.start, span.end));
    }

    let mut seen_keys: FxHashSet<(usize, usize)> =
        FxHashSet::with_capacity_and_hasher(current.len(), Default::default());
    let mut filtered: Vec<SpanRecord<'a>> = Vec::with_capacity(current.len() + previous.len());

    for span in current {
        let key = (span.start, span.end);
        if prev_keys.contains(&key) || !seen_keys.insert(key) {
            continue;
        }
        filtered.push(span);
    }

    filtered.extend_from_slice(previous);
    filtered
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn face_mark_detection_matches_reference() {
        let text = "顔文字(*^_^*)だよ。";
        let view = TextView::new(text);
        let spans = find_face_marks(&view);
        assert_eq!(spans.len(), 1);
        let span = &spans[0];
        assert_eq!(span.start, 3);
        assert_eq!(span.end, 10);
        assert_eq!(span.split_value, Some("(*^_^*)"));
    }

    #[test]
    fn indirect_quote_handles_question_particle_followed_by_to() {
        let text = "スタッフ? と話し込み。";
        let view = TextView::new(text);
        let spans = build_basic_rule_spans(&view);
        let target = spans
            .iter()
            .find(|span| span.start == 4 && span.end == 6)
            .expect("expected basic rule span");
        assert!(is_exception_particle(&view, target.start, target.end));
    }

    #[test]
    fn segment_pipeline_matches_bunkai_for_staff_question_case() {
        let text = "スタッフ? と話し込み。";
        let output = Segmenter::new().segment(text);
        assert_eq!(output.final_boundaries, vec![12]);
    }
}
